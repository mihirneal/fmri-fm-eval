{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9910d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95bd9069",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183ec0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(path: Path):\n",
    "    # Brown/sub-0026001/ses-1/func/sub-0026001_ses-1_task-rest_run-1_bold.nii.gz\n",
    "    dataset = path.parts[0]\n",
    "    site = dataset.split(\"_\")[0]  # Peking_1 -> Peking\n",
    "    stem, ext = path.name.split(\".\", 1)\n",
    "    stem, suffix = stem.rsplit(\"_\", 1)\n",
    "    meta = dict(item.split(\"-\") for item in stem.split(\"_\") if \"-\" in item)\n",
    "    # set sometimes missing keys\n",
    "    for k in [\"task\", \"run\", \"acq\"]:\n",
    "        meta[k] = meta.get(k)\n",
    "    meta = {\"site\": site, \"dataset\": dataset, **meta, \"suffix\": suffix}\n",
    "    return meta\n",
    "\n",
    "\n",
    "def read_header(path: Path):\n",
    "    img = nib.load(path, mmap=True)\n",
    "    shape = list(img.shape)\n",
    "    if len(shape) == 4:\n",
    "        tr = round(float(img.header[\"pixdim\"][4]), 2)\n",
    "        num_trs = shape[-1]\n",
    "        dur = num_trs * tr\n",
    "    else:\n",
    "        tr = num_trs = dur = None\n",
    "    info = {\"tr\": tr, \"num_trs\": num_trs, \"dur\": dur}\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a0d1e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num fmriprep mni paths: 1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1390/1390 [00:02<00:00, 513.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# index all the completed fmriprep data\n",
    "fmriprep_root = ROOT / \"data/fmriprep\"\n",
    "mni_path_list = sorted(\n",
    "    fmriprep_root.rglob(\"*_space-MNI152NLin6Asym_res-2_desc-preproc_bold.nii.gz\")\n",
    ")\n",
    "print(f\"num fmriprep mni paths: {len(mni_path_list)}\")\n",
    "\n",
    "bids_index_path = Path(ROOT / \"metadata/ADHD200_BIDS_index.csv\")\n",
    "\n",
    "if not bids_index_path.exists():\n",
    "    records = []\n",
    "    for mni_path in tqdm(mni_path_list):\n",
    "        original_path = mni_path.parent / mni_path.name.replace(\n",
    "            \"_space-MNI152NLin6Asym_res-2_desc-preproc_bold.nii.gz\",\n",
    "            \"_bold.nii.gz\",\n",
    "        )\n",
    "        original_path = original_path.relative_to(fmriprep_root)\n",
    "        meta = parse_metadata(original_path)\n",
    "\n",
    "        info = read_header(mni_path)\n",
    "\n",
    "        cifti_path = mni_path.parent / mni_path.name.replace(\n",
    "            \"_space-MNI152NLin6Asym_res-2_desc-preproc_bold.nii.gz\",\n",
    "            \"_space-fsLR_den-91k_bold.dtseries.nii\",\n",
    "        )\n",
    "\n",
    "        record = {\n",
    "            **meta,\n",
    "            **info,\n",
    "            \"has_mni\": mni_path.exists(),\n",
    "            \"has_cifti\": cifti_path.exists(),\n",
    "            \"path\": str(original_path),\n",
    "        }\n",
    "        records.append(record)\n",
    "\n",
    "    bids_df = pd.DataFrame.from_records(records)\n",
    "    bids_df.to_csv(bids_index_path, index=False)\n",
    "\n",
    "bids_df = pd.read_csv(bids_index_path, dtype={\"sub\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b386cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1390, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>dataset</th>\n",
       "      <th>sub</th>\n",
       "      <th>ses</th>\n",
       "      <th>task</th>\n",
       "      <th>run</th>\n",
       "      <th>acq</th>\n",
       "      <th>suffix</th>\n",
       "      <th>tr</th>\n",
       "      <th>num_trs</th>\n",
       "      <th>dur</th>\n",
       "      <th>has_mni</th>\n",
       "      <th>has_cifti</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brown</td>\n",
       "      <td>Brown</td>\n",
       "      <td>0026001</td>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bold</td>\n",
       "      <td>2.0</td>\n",
       "      <td>251</td>\n",
       "      <td>502.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Brown/sub-0026001/ses-1/func/sub-0026001_ses-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brown</td>\n",
       "      <td>Brown</td>\n",
       "      <td>0026002</td>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bold</td>\n",
       "      <td>2.0</td>\n",
       "      <td>251</td>\n",
       "      <td>502.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Brown/sub-0026002/ses-1/func/sub-0026002_ses-1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    site dataset      sub  ses  task  run  acq suffix   tr  num_trs    dur  \\\n",
       "0  Brown   Brown  0026001    1  rest    1  NaN   bold  2.0      251  502.0   \n",
       "1  Brown   Brown  0026002    1  rest    1  NaN   bold  2.0      251  502.0   \n",
       "\n",
       "   has_mni  has_cifti                                               path  \n",
       "0     True       True  Brown/sub-0026001/ses-1/func/sub-0026001_ses-1...  \n",
       "1     True       True  Brown/sub-0026002/ses-1/func/sub-0026002_ses-1...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(bids_df.shape)\n",
    "bids_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed6a98b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 path\n",
      "dataset    tr        \n",
      "Brown      2.00    26\n",
      "KKI        2.50    83\n",
      "NYU        2.00   435\n",
      "NeuroIMAGE 1.96    73\n",
      "OHSU       2.50   268\n",
      "Peking_1   2.00   136\n",
      "Peking_2   2.00    67\n",
      "Peking_3   2.00    41\n",
      "Pittsburgh 1.50    88\n",
      "           3.00     8\n",
      "WashU      2.50   165\n"
     ]
    }
   ],
   "source": [
    "# look at trs\n",
    "print(bids_df.groupby([\"dataset\", \"tr\"]).agg({\"path\": \"count\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d9ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   path\n",
      "dataset    dur         \n",
      "Brown      502.00    26\n",
      "KKI        310.00    54\n",
      "           380.00    29\n",
      "NYU        350.00    41\n",
      "           352.00   394\n",
      "NeuroIMAGE 509.60     5\n",
      "           511.56    68\n",
      "OHSU       147.50     1\n",
      "           190.00     3\n",
      "           192.50    34\n",
      "           195.00   230\n",
      "Peking_1   470.00    51\n",
      "           472.00    85\n",
      "Peking_2   472.00    67\n",
      "Peking_3   472.00    41\n",
      "Pittsburgh 294.00    88\n",
      "           369.00     7\n",
      "           588.00     1\n",
      "WashU      190.00    24\n",
      "           330.00   112\n",
      "           332.50    29\n"
     ]
    }
   ],
   "source": [
    "# look at durations\n",
    "# most longer than 5 min\n",
    "print(bids_df.groupby([\"dataset\", \"dur\"]).agg({\"path\": \"count\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd06852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num valid bold runs: 1010 / 1390\n"
     ]
    }
   ],
   "source": [
    "# include runs with complete preprocessed outputs and at least 5 min long\n",
    "bids_mask = (bids_df[\"has_mni\"]) & (bids_df[\"has_cifti\"]) & (bids_df[\"dur\"] > 5 * 60)\n",
    "print(f\"num valid bold runs: {bids_mask.sum()} / {len(bids_mask)}\")\n",
    "bids_df_clean = bids_df.loc[bids_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae2086a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num pheno csvs: 9\n"
     ]
    }
   ],
   "source": [
    "# get phenotype data\n",
    "# downloaded from s3://fcp-indi/data/Projects/ADHD200/RawDataBIDS/*_phenotypic.csv\n",
    "pheno_paths = sorted((ROOT / \"data/phenotypic\").glob(\"*_phenotypic.csv\"))\n",
    "print(f\"num pheno csvs: {len(pheno_paths)}\")\n",
    "assert len(pheno_paths) == 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "821d178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(717, 24)\n",
      "   ScanDir ID  Site  Gender    Age Handedness       DX\n",
      "0     26001.0     2     1.0  16.92          1  pending\n",
      "1     26002.0     2     1.0  15.68          1  pending\n",
      "2     26004.0     2     0.0  14.99          1  pending\n"
     ]
    }
   ],
   "source": [
    "pheno_df = pd.concat([pd.read_csv(path) for path in pheno_paths], ignore_index=True)\n",
    "print(pheno_df.shape)\n",
    "print(pheno_df.iloc[:3, :6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885dcec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site\n",
      "5    222\n",
      "1    136\n",
      "6    113\n",
      "7     89\n",
      "3     83\n",
      "4     48\n",
      "2     26\n",
      "Name: count, dtype: int64\n",
      "Gender\n",
      "1.0    401\n",
      "0.0    315\n",
      "Name: count, dtype: int64\n",
      "DX\n",
      "0          430\n",
      "1          154\n",
      "3           94\n",
      "pending     26\n",
      "2           13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pheno_df[\"Site\"].value_counts())\n",
    "print(pheno_df[\"Gender\"].value_counts())\n",
    "print(pheno_df[\"DX\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cab64725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap integer ids to text labels\n",
    "# https://fcon_1000.projects.nitrc.org/indi/adhd200/general/ADHD-200_PhenotypicKey.pdf\n",
    "\n",
    "site_map = {\n",
    "    1: \"Peking\",\n",
    "    2: \"Brown\",\n",
    "    3: \"KKI\",\n",
    "    4: \"NeuroIMAGE\",\n",
    "    5: \"NYU\",\n",
    "    6: \"OHSU\",\n",
    "    7: \"Pittsburgh\",\n",
    "    8: \"WashU\",\n",
    "}\n",
    "\n",
    "gender_map = {\n",
    "    0: \"F\",\n",
    "    1: \"M\",\n",
    "}\n",
    "\n",
    "# merge all adhd diagnosis categories\n",
    "dx_map = {\n",
    "    0: \"Control\",  # Typically Developing Children\n",
    "    1: \"ADHD\",  # ADHD-Combined\n",
    "    2: \"ADHD\",  # ADHD-Hyperactive/Impulsive\n",
    "    3: \"ADHD\",  # ADHD-Inattentive\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1188b440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site\n",
      "NYU           214\n",
      "Peking         85\n",
      "KKI            83\n",
      "NeuroIMAGE     48\n",
      "Pittsburgh      1\n",
      "Name: count, dtype: int64\n",
      "num valid subs: 430 / 717\n",
      "(430, 5)\n",
      "       sub site gender       dx    age\n",
      "0  0010001  NYU      F     ADHD  11.17\n",
      "1  0010002  NYU      F     ADHD  13.24\n",
      "2  0010003  NYU      F  Control   9.29\n",
      "3  0010004  NYU      F  Control  13.75\n",
      "4  0010005  NYU      M     ADHD  11.92\n"
     ]
    }
   ],
   "source": [
    "# clean up the phenotype table\n",
    "pheno_df_clean = pheno_df.loc[:, [\"ScanDir ID\", \"Site\", \"Gender\", \"Age\", \"DX\"]].copy()\n",
    "pheno_df_clean = pheno_df_clean.dropna()\n",
    "\n",
    "# drop subs with \"pending\" dx (idk what that is)\n",
    "pheno_df_clean = pheno_df_clean.loc[pheno_df_clean[\"DX\"] != \"pending\"]\n",
    "\n",
    "# format columns\n",
    "pheno_df_clean[\"sub\"] = [f\"{int(subid):07d}\" for subid in pheno_df_clean[\"ScanDir ID\"]]\n",
    "pheno_df_clean[\"site\"] = pheno_df_clean[\"Site\"].map(site_map)\n",
    "pheno_df_clean[\"gender\"] = pheno_df_clean[\"Gender\"].map(gender_map)\n",
    "pheno_df_clean[\"age\"] = pheno_df_clean[\"Age\"]\n",
    "pheno_df_clean[\"dx\"] = [dx_map[int(dx)] for dx in pheno_df_clean[\"DX\"]]\n",
    "\n",
    "pheno_df_clean = pheno_df_clean.loc[:, [\"sub\", \"site\", \"gender\", \"dx\", \"age\"]]\n",
    "\n",
    "# remove subs that are missing image data\n",
    "pheno_df_clean = pheno_df_clean.loc[pheno_df_clean[\"sub\"].isin(bids_df_clean[\"sub\"])]\n",
    "\n",
    "# drop sites with too few subjects\n",
    "site_counts = pheno_df_clean[\"site\"].value_counts()\n",
    "print(site_counts)\n",
    "include_sites = [site for site, count in site_counts.items() if count >= 10]\n",
    "pheno_df_clean = pheno_df_clean.loc[pheno_df_clean[\"site\"].isin(include_sites)]\n",
    "\n",
    "pheno_df_clean = pheno_df_clean.sort_values(\"sub\")\n",
    "pheno_df_clean = pheno_df_clean.reset_index(drop=True)\n",
    "\n",
    "print(f\"num valid subs: {len(pheno_df_clean)} / {len(pheno_df)}\")\n",
    "print(pheno_df_clean.shape)\n",
    "print(pheno_df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5739fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 301 | Val: 64 | Test: 65\n"
     ]
    }
   ],
   "source": [
    "# splits\n",
    "\n",
    "# Create a Combined Stratification Column\n",
    "strat_key = (pheno_df_clean[\"gender\"].astype(str) + \"_\" + pheno_df_clean[\"dx\"].astype(str)).values\n",
    "\n",
    "# Perform the Split (70% Train, 15% Val, 15% Test)\n",
    "# First split: 70% Train, 30% Temp (which will be Val + Test)\n",
    "train_ids, temp_ids = train_test_split(\n",
    "    np.arange(len(pheno_df_clean)), test_size=0.30, random_state=42, stratify=strat_key\n",
    ")\n",
    "\n",
    "# Second split: Divide the 30% Temp into 50/50 Val and Test\n",
    "val_ids, test_ids = train_test_split(\n",
    "    temp_ids, test_size=0.50, random_state=42, stratify=strat_key[temp_ids]\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_ids)} | Val: {len(val_ids)} | Test: {len(test_ids)}\")\n",
    "\n",
    "splits = np.full(len(pheno_df_clean), None, dtype=object)\n",
    "splits[train_ids] = \"train\"\n",
    "splits[val_ids] = \"validation\"\n",
    "splits[test_ids] = \"test\"\n",
    "pheno_df_clean[\"split\"] = pd.Categorical(\n",
    "    splits, categories=[\"train\", \"validation\", \"test\"], ordered=True\n",
    ")\n",
    "\n",
    "pheno_df_clean = pheno_df_clean.sort_values([\"split\", \"sub\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff68cdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| split      |   Total |   ADHD |   Control |   Female |   Male |\n",
      "|:-----------|--------:|-------:|----------:|---------:|-------:|\n",
      "| train      |     301 |    131 |       170 |      128 |    173 |\n",
      "| validation |      64 |     28 |        36 |       27 |     37 |\n",
      "| test       |      65 |     28 |        37 |       28 |     37 |\n"
     ]
    }
   ],
   "source": [
    "combined_counts = pheno_df_clean.groupby([\"split\"], observed=False).agg(\n",
    "    {\n",
    "        \"sub\": [(\"Total\", \"count\")],\n",
    "        \"dx\": [\n",
    "            (\"ADHD\", lambda s: (s == \"ADHD\").sum()),\n",
    "            (\"Control\", lambda s: (s == \"Control\").sum()),\n",
    "        ],\n",
    "        \"gender\": [\n",
    "            (\"Female\", lambda s: (s == \"F\").sum()),\n",
    "            (\"Male\", lambda s: (s == \"M\").sum()),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "combined_counts.columns = combined_counts.columns.get_level_values(1)\n",
    "combined_counts = combined_counts.reset_index()\n",
    "print(combined_counts.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a37380c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430, 18)\n",
      "       sub site gender       dx    age  split dataset  ses  task  run  acq  \\\n",
      "0  0010001  NYU      F     ADHD  11.17  train     NYU    1  rest    1  NaN   \n",
      "2  0010002  NYU      F     ADHD  13.24  train     NYU    1  rest    1  NaN   \n",
      "4  0010003  NYU      F  Control   9.29  train     NYU    1  rest    1  NaN   \n",
      "5  0010006  NYU      F  Control  11.18  train     NYU    1  rest    1  NaN   \n",
      "6  0010007  NYU      F     ADHD  11.41  train     NYU    1  rest    1  NaN   \n",
      "\n",
      "  suffix   tr  num_trs    dur  has_mni  has_cifti  \\\n",
      "0   bold  2.0      176  352.0     True       True   \n",
      "2   bold  2.0      176  352.0     True       True   \n",
      "4   bold  2.0      176  352.0     True       True   \n",
      "5   bold  2.0      176  352.0     True       True   \n",
      "6   bold  2.0      176  352.0     True       True   \n",
      "\n",
      "                                                path  \n",
      "0  NYU/sub-0010001/ses-1/func/sub-0010001_ses-1_t...  \n",
      "2  NYU/sub-0010002/ses-1/func/sub-0010002_ses-1_t...  \n",
      "4  NYU/sub-0010003/ses-1/func/sub-0010003_ses-1_t...  \n",
      "5  NYU/sub-0010006/ses-1/func/sub-0010006_ses-1_t...  \n",
      "6  NYU/sub-0010007/ses-1/func/sub-0010007_ses-1_t...  \n"
     ]
    }
   ],
   "source": [
    "merged_df = pheno_df_clean.merge(bids_df_clean, on=[\"sub\", \"site\"], how=\"inner\")\n",
    "\n",
    "# only keep one run per sub\n",
    "merged_df = merged_df.drop_duplicates(\"sub\")\n",
    "assert len(merged_df) == len(pheno_df_clean)\n",
    "\n",
    "print(merged_df.shape)\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81104193",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(ROOT / \"metadata/ADHD200_curated.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-fm-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
